{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling\n",
    "\n",
    "The [topicmod module](api.rst#module-tmtoolkit.topicmod) offers a wide range of tools to facilitate [topic modeling](https://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext) with Python. This chapter will introduce the following techniques: \n",
    "\n",
    "TODO (link this)\n",
    "\n",
    "- [parallel topic model computation for different copora and/or parameter sets](#Computing-topic-models-in-parallel)\n",
    "- [evaluation of topic models (including finding a good set of hyperparameters for the given dataset)](#Evaluation-of-topic-models)\n",
    "- [common statistics for topic models](#Common-statistics-for-topic-models)\n",
    "- [export of topic models and summaries to different file formats](#Displaying-and-exporting-topic-modeling-results)\n",
    "- visualization of topic models\n",
    "\n",
    "A quick note on terminology: So far, we spoke about *tokens* or sometimes *terms* when we meant the individual elements that our documents consist of after we applied text preprocessing such as *tokenization* to the raw input text strings. These tokens can be lexicographically correct words, but they don't have to, e.g. when you applied stemming you might have tokens like \"argu\" in your vocabulary. There may also be numbers or punctuation symbols in your vocabulary. For many traditional topic modeling techniques, the results are usually two probability distributions: a *document-topic distribution* and a *topic-word distribution*. Since the latter is called topic-*word* and not topic-*token* or *-term* distribution, we will also use the term *word* when we mean any token from the corpus' vocabulary.\n",
    "\n",
    "\n",
    "## An example document-term matrix\n",
    "\n",
    "tmtoolkit supports topic models that are computed from document-term matrices (DTMs). Just as in the previous chapter, we will at first generate a DTM. However, this time the sample will be bigger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Corpus [100 documents]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(20191120)   # to make the sampling reproducible\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "from tmtoolkit.corpus import Corpus\n",
    "\n",
    "# for topic modeling, the document sizes shouldn't be\n",
    "# too different, hence we set a filter\n",
    "corpus = Corpus.from_builtin_corpus('english-NewsArticles') \\\n",
    "    .filter_by_min_length(1000) \\\n",
    "    .filter_by_max_length(10000) \\\n",
    "    .sample(100)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also now generate two DTMs, because we later want to show how you can compute topic models for two different DTMs in parallel. At first, we to some general preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TMPreproc [100 documents]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.preprocess import TMPreproc\n",
    "\n",
    "preproc = TMPreproc(corpus)\n",
    "preproc.pos_tag() \\\n",
    "    .lemmatize() \\\n",
    "    .tokens_to_lowercase() \\\n",
    "    .remove_special_chars_in_tokens()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we at first apply more \"relaxed\" cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 866)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_bigger = preproc.copy() \\\n",
    "    .add_stopwords(['would', 'could', 'nt', 'mr', 'mrs', 'also']) \\\n",
    "    .clean_tokens(remove_shorter_than=2) \\\n",
    "    .remove_common_tokens(df_threshold=0.85) \\\n",
    "    .remove_uncommon_tokens(df_threshold=0.05)\n",
    "\n",
    "preproc_bigger.n_docs, preproc_bigger.vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another copy of `preproc` will apply more aggressive cleaning and hence in a smaller vocabulary size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 156)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_smaller = preproc.copy() \\\n",
    "    .filter_for_pos('N') \\\n",
    "    .clean_tokens(remove_numbers=True, remove_shorter_than=2) \\\n",
    "    .remove_common_tokens(df_threshold=0.9) \\\n",
    "    .remove_uncommon_tokens(df_threshold=0.1)\n",
    "\n",
    "del preproc\n",
    "\n",
    "preproc_smaller.n_docs, preproc_smaller.vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create the document labels, vocabulary arrays and DTMs for both versions now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NewsArticles-1041', 'NewsArticles-1065', 'NewsArticles-1099',\n",
       "       'NewsArticles-1169', 'NewsArticles-1174', 'NewsArticles-1184',\n",
       "       'NewsArticles-1189', 'NewsArticles-120', 'NewsArticles-1237',\n",
       "       'NewsArticles-1282'], dtype='<U17')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_labels are the same for both\n",
    "\n",
    "doc_labels = np.array(preproc_bigger.doc_labels)\n",
    "doc_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_bg = np.array(preproc_bigger.vocabulary)\n",
    "vocab_sm = np.array(preproc_smaller.vocabulary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<100x866 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 10860 stored elements in Compressed Sparse Row format>,\n",
       " <100x156 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 2785 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_bg = preproc_bigger.dtm\n",
    "dtm_sm = preproc_smaller.dtm\n",
    "\n",
    "del preproc_bigger, preproc_smaller  # don't need these any more\n",
    "\n",
    "dtm_bg, dtm_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two sparse DTMs `dtm_bg` (from the bigger preprocessed data) and `dtm_sm` (from the smaller preprocessed data), a list of document labels `doc_labels` that represent the rows of both DTMs and vocabulary arrays `vocab_bg` and `vocab_sm` that represent the columns of the respective DTMs. We will use this data for the remainder of the chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing topic models in parallel\n",
    "\n",
    "tmtoolkit allows to compute topic models in parallel, making use of all processor cores in your machine. Parallelization can be done per input DTM, per hyperparameter set and as combination of both. Hyperparameters control the number of topics and their \"granularity\". We will later have a look at the role of hyperparameters and how to find an optimal combination for a given dataset with the means of topic model evaluation.\n",
    "\n",
    "For now, we will concentrate on computing the topic models for both of our two DTMs in parallel. tmtoolkit supports three very popular packages for topic modeling, which provide the work of actually computing the model from the input matrix. They can all be accessed in separate sub-modules of the [topicmod module](api.rst#module-tmtoolkit.topicmod):\n",
    "\n",
    "- [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda) provides an interface for the [lda](https://lda.readthedocs.io/en/latest/) package\n",
    "- [topicmod.tm_sklearn](api.html#module-tmtoolkit.topicmod.tm_sklearn) provides an interface for the [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) package\n",
    "- [topicmod.tm_gensim](api.html#module-tmtoolkit.topicmod.tm_gensim) provides an interface for the [Gensim](https://radimrehurek.com/gensim/) package\n",
    "\n",
    "Each of these sub-modules offer at least two functions that work with the respective package: `compute_models_parallel()` for general parallel model computation and `evaluate_topic_models()` for parallel model computation and evaluation (discussed later). For now, we want to compute two models in parallel with the [lda](https://lda.readthedocs.io/en/latest/) package and hence use [compute_models_parallel()](api.rst#tmtoolkit.topicmod.tm_lda.compute_models_parallel) from [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda).\n",
    "\n",
    "We need to provide two things for this function: First, the input matrices as a dict that maps labels to the respective DTMs. Second, hyperparameters to use for the model computations. Note that each topic modeling package has different hyperparameters and you should refer to their documentation in order to find out, which hyperparameters you can provide. For lda, we set the number of topics `n_topics` to 10 and the number of iterations for the Gibbs sampling process `n_iter` to 1000. We always want to use the same hyperparameters, so we pass these as `constant_parameters`. If we wanted to create models for a whole range of parameters, e.g. for different numbers of topics, we could provide `varying_parameters`. We will check this out later when we evaluate topic models.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Note that for proper topic modeling, we shouldn't just set the number of topics, but try to find it out via evaluation methods. We should also check if the algorithm converged using the provided likelihood estimations. We will do both later on, but now focus on `compute_models_parallel()`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'smaller': [({'n_topics': 10,\n",
       "                'n_iter': 1000,\n",
       "                'random_state': 20191122},\n",
       "               <lda.lda.LDA at 0x7f777c1c6668>)],\n",
       "             'bigger': [({'n_topics': 10,\n",
       "                'n_iter': 1000,\n",
       "                'random_state': 20191122},\n",
       "               <lda.lda.LDA at 0x7f777c2ae4a8>)]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from tmtoolkit.topicmod.tm_lda import compute_models_parallel\n",
    "\n",
    "# suppress the \"INFO\" messages and warnings from lda\n",
    "logger = logging.getLogger('lda')\n",
    "logger.addHandler(logging.NullHandler())\n",
    "logger.propagate = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set data to use\n",
    "dtms = {\n",
    "    'bigger': dtm_bg,\n",
    "    'smaller': dtm_sm\n",
    "}\n",
    "\n",
    "# and fixed hyperparameters\n",
    "lda_params = {\n",
    "    'n_topics': 10,\n",
    "    'n_iter': 1000,\n",
    "    'random_state': 20191122  # to make results reproducible\n",
    "}\n",
    "\n",
    "models = compute_models_parallel(dtms, constant_parameters=lda_params)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, two models were created. These can be accessed via the labels that we used to define the `dtm` dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'n_topics': 10, 'n_iter': 1000, 'random_state': 20191122},\n",
       "  <lda.lda.LDA at 0x7f777c1c6668>)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['smaller']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for each input DTM, we get a list of 2-tuples. The first element in each tuple is a dict that represents the hyperparameters that were used to compute the model, the second element is actual topic model (the `<lda.lda.LDA ...>` object). This structure looks a bit complex, but this is because it also supports varying parameters. Since we only have one fixed set of hyperparameters per DTM, we only have a list of length 1 for each DTM.\n",
    "\n",
    "We will now access the models and print the top words per topic by using [print_ldamodel_topic_words()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_topic_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_1\n",
      "> #1. child (0.100100)\n",
      "> #2. state (0.087127)\n",
      "> #3. police (0.076006)\n",
      "topic_2\n",
      "> #1. minister (0.076240)\n",
      "> #2. deal (0.066211)\n",
      "> #3. party (0.062199)\n",
      "topic_3\n",
      "> #1. russia (0.165184)\n",
      "> #2. threat (0.073712)\n",
      "> #3. february (0.066089)\n",
      "topic_4\n",
      "> #1. group (0.097418)\n",
      "> #2. attack (0.064261)\n",
      "> #3. force (0.058045)\n",
      "topic_5\n",
      "> #1. house (0.170026)\n",
      "> #2. white (0.099919)\n",
      "> #3. president (0.089403)\n",
      "topic_6\n",
      "> #1. trump (0.224533)\n",
      "> #2. president (0.121897)\n",
      "> #3. administration (0.075390)\n",
      "topic_7\n",
      "> #1. year (0.100786)\n",
      "> #2. court (0.078077)\n",
      "> #3. day (0.049691)\n",
      "topic_8\n",
      "> #1. us (0.358221)\n",
      "> #2. united (0.093928)\n",
      "> #3. states (0.076541)\n",
      "topic_9\n",
      "> #1. china (0.181912)\n",
      "> #2. company (0.110824)\n",
      "> #3. year (0.093052)\n",
      "topic_10\n",
      "> #1. people (0.143312)\n",
      "> #2. government (0.080095)\n",
      "> #3. health (0.063238)\n"
     ]
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import print_ldamodel_topic_words\n",
    "\n",
    "model_sm = models['smaller'][0][1]\n",
    "print_ldamodel_topic_words(model_sm.topic_word_, vocab_sm, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_1\n",
      "> #1. russia (0.057998)\n",
      "> #2. vote (0.033534)\n",
      "> #3. russian (0.032628)\n",
      "topic_2\n",
      "> #1. us (0.042852)\n",
      "> #2. people (0.030392)\n",
      "> #3. take (0.027657)\n",
      "topic_3\n",
      "> #1. year (0.057346)\n",
      "> #2. first (0.023742)\n",
      "> #3. last (0.022817)\n",
      "topic_4\n",
      "> #1. one (0.035330)\n",
      "> #2. get (0.030228)\n",
      "> #3. go (0.024732)\n",
      "topic_5\n",
      "> #1. death (0.049719)\n",
      "> #2. court (0.041434)\n",
      "> #3. police (0.031642)\n",
      "topic_6\n",
      "> #1. trump (0.089177)\n",
      "> #2. president (0.074211)\n",
      "> #3. house (0.059869)\n",
      "topic_7\n",
      "> #1. china (0.117126)\n",
      "> #2. chinese (0.038374)\n",
      "> #3. million (0.034335)\n",
      "topic_8\n",
      "> #1. north (0.092136)\n",
      "> #2. south (0.063956)\n",
      "> #3. two (0.031442)\n",
      "topic_9\n",
      "> #1. company (0.044429)\n",
      "> #2. market (0.043636)\n",
      "> #3. european (0.040463)\n",
      "topic_10\n",
      "> #1. child (0.036569)\n",
      "> #2. state (0.029752)\n",
      "> #3. tell (0.029133)\n"
     ]
    }
   ],
   "source": [
    "model_bg = models['bigger'][0][1]\n",
    "print_ldamodel_topic_words(model_bg.topic_word_, vocab_bg, top_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also generate models from different parameters in parallel, either for a single DTM or several. In the following example we generate models for a series of four different values for the `alpha` parameter. The parameters `n_iter` and `n_topics` are held constant across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'alpha': 0.0001, 'n_iter': 500, 'n_topics': 10, 'random_state': 20191122},\n",
       "  <lda.lda.LDA at 0x7f776f7f9518>),\n",
       " ({'alpha': 0.001, 'n_iter': 500, 'n_topics': 10, 'random_state': 20191122},\n",
       "  <lda.lda.LDA at 0x7f776f7f90f0>),\n",
       " ({'alpha': 0.01, 'n_iter': 500, 'n_topics': 10, 'random_state': 20191122},\n",
       "  <lda.lda.LDA at 0x7f777c177ba8>),\n",
       " ({'alpha': 0.1, 'n_iter': 500, 'n_topics': 10, 'random_state': 20191122},\n",
       "  <lda.lda.LDA at 0x7f777c07d400>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_params = [{'alpha': 1/(10**x)} for x in range(1, 5)]\n",
    "\n",
    "const_params = {\n",
    "    'n_iter': 500,\n",
    "    'n_topics': 10,\n",
    "    'random_state': 20191122  # to make results reproducible\n",
    "}\n",
    "\n",
    "models = compute_models_parallel(dtm_sm,  # smaller DTM\n",
    "                                 varying_parameters=var_params,\n",
    "                                 constant_parameters=const_params)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could compare these models now, e.g. by investigating their topics.\n",
    "\n",
    "A more systematic approach on comparing and evaluating topic models, also in order to find an good set of hyperparameters for a given dataset, will be presented in the next section.\n",
    "\n",
    "## Evaluation of topic models\n",
    "\n",
    "tmtoolkit provides several metrics for comparing and evaluating topic models. This can be used for finding a good hyperparameter set for a given dataset, e.g. a good combination of the number of topics and concentration paramaters (often called alpha and beta in literature). For some background on hyperparameters in topic modeling, see [this blog post](https://datascience.blog.wzb.eu/2017/11/09/topic-modeling-evaluation-in-python-with-tmtoolkit/).\n",
    "\n",
    "For each candidate hyperparameter set, a model can be generated and evaluated in parallel. We will do this now for the \"big\" DTM `dtm_bg`. Our candidate values for the number of topics `k` range between 20 and 120, with steps of 10. We make the concentration parameter for a prior over the document-specific topic distributions, alpha, depending on `k` as `1/k`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n_topics': 20, 'alpha': 0.05},\n",
       " {'n_topics': 30, 'alpha': 0.03333333333333333},\n",
       " {'n_topics': 40, 'alpha': 0.025},\n",
       " {'n_topics': 50, 'alpha': 0.02},\n",
       " {'n_topics': 60, 'alpha': 0.016666666666666666},\n",
       " {'n_topics': 70, 'alpha': 0.014285714285714285},\n",
       " {'n_topics': 80, 'alpha': 0.0125},\n",
       " {'n_topics': 90, 'alpha': 0.011111111111111112},\n",
       " {'n_topics': 100, 'alpha': 0.01},\n",
       " {'n_topics': 110, 'alpha': 0.00909090909090909},\n",
       " {'n_topics': 120, 'alpha': 0.008333333333333333}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_params = [{'n_topics': k, 'alpha': 1/k} for k in range(20, 121, 10)]\n",
    "var_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heart of the model evaluation process is the function [evaluate_topic_models()](api.rst#tmtoolkit.topicmod.tm_lda.evaluate_topic_models), which is available for all three topic modeling packages. We stick with lda and import that function from [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda). It is similar to [compute_models_parallel()](api.rst#tmtoolkit.topicmod.tm_lda.compute_models_parallel) as it accepts varying and constant hyperparameters. However, it doesn't only compute the models in parallel, but also applies several metrics to these models in order to evaluate them. This can be controlled with the `metric` parameter that accepts a string or a list of strings that specify the used metric(s). These metrics refer to functions that are implemented in [topicmod.evaluate](api.rst#module-tmtoolkit.topicmod.evaluate).\n",
    "\n",
    "Each topic modeling sub-module defines two important sequences: `AVAILABLE_METRICS` and `DEFAULT_METRICS`. The former lists all available metrics for that sub-module, the latter lists the default metrics that are used when you don't specify something with the `metric` parameter. Let's have a look at both sequences in [topicmod.tm_lda](api.html#module-tmtoolkit.topicmod.tm_lda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('loglikelihood',\n",
       " 'cao_juan_2009',\n",
       " 'arun_2010',\n",
       " 'coherence_mimno_2011',\n",
       " 'griffiths_2004',\n",
       " 'held_out_documents_wallach09',\n",
       " 'coherence_gensim_u_mass',\n",
       " 'coherence_gensim_c_v',\n",
       " 'coherence_gensim_c_uci',\n",
       " 'coherence_gensim_c_npmi')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod import tm_lda\n",
    "\n",
    "tm_lda.AVAILABLE_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cao_juan_2009', 'arun_2010', 'coherence_mimno_2011')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_lda.DEFAULT_METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For details about the metrics and the academic references, see the respective implementations in the [topicmod.evaluate](api.rst#module-tmtoolkit.topicmod.evaluate) module.\n",
    "\n",
    "We will now run the model evaluations with [evaluate_topic_models()](api.rst#tmtoolkit.topicmod.tm_lda.evaluate_topic_models) using our previously generated list of varying hyperparameters `var_params`, some constant hyperparameters and the default set of metrics. We also set `return_models=True` which says to retain the generated models in the evaluation results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'n_topics': 20,\n",
       "   'alpha': 0.05,\n",
       "   'n_iter': 1000,\n",
       "   'eta': 0.1,\n",
       "   'random_state': 20191122},\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07deb8>,\n",
       "   'cao_juan_2009': 0.11481331353994903,\n",
       "   'arun_2010': 10.81440771487237,\n",
       "   'coherence_mimno_2011': -1.5705955029901921}),\n",
       " ({'n_topics': 30,\n",
       "   'alpha': 0.03333333333333333,\n",
       "   'n_iter': 1000,\n",
       "   'eta': 0.1,\n",
       "   'random_state': 20191122},\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07d358>,\n",
       "   'cao_juan_2009': 0.11299796966131251,\n",
       "   'arun_2010': 6.3501538041085475,\n",
       "   'coherence_mimno_2011': -1.5797425879990783}),\n",
       " ({'n_topics': 40,\n",
       "   'alpha': 0.025,\n",
       "   'n_iter': 1000,\n",
       "   'eta': 0.1,\n",
       "   'random_state': 20191122},\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07d208>,\n",
       "   'cao_juan_2009': 0.11013624472342246,\n",
       "   'arun_2010': 4.853368419225177,\n",
       "   'coherence_mimno_2011': -1.6514230985163838})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.tm_lda import evaluate_topic_models\n",
    "from tmtoolkit.topicmod.evaluate import results_by_parameter\n",
    "\n",
    "const_params = {\n",
    "    'n_iter': 1000,\n",
    "    'eta': 0.1,       # \"eta\" aka \"beta\"\n",
    "    'random_state': 20191122  # to make results reproducible\n",
    "}\n",
    "\n",
    "eval_results = evaluate_topic_models(dtm_bg,\n",
    "                                     varying_parameters=var_params,\n",
    "                                     constant_parameters=const_params,\n",
    "                                     return_models=True)\n",
    "eval_results[:3]  # only show first three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation results are a list with pairs of hyperparameters and their evaluation results for each metric. Additionally, there is the generated model for each hyperparameter set.\n",
    "\n",
    "We now use [results_by_parameter()](api.rst#tmtoolkit.topicmod.evaluate.results_by_parameter), which takes the \"raw\" evaluation results and sorts them by a specific hyperparameter, in this case `n_topics`. This is important because this is the way that the function for visualizing evaluation results, [plot_eval_results()](api.rst#tmtoolkit.topicmod.visualize.plot_eval_results), expects the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20,\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07deb8>,\n",
       "   'cao_juan_2009': 0.11481331353994903,\n",
       "   'arun_2010': 10.81440771487237,\n",
       "   'coherence_mimno_2011': -1.5705955029901921}),\n",
       " (30,\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07d358>,\n",
       "   'cao_juan_2009': 0.11299796966131251,\n",
       "   'arun_2010': 6.3501538041085475,\n",
       "   'coherence_mimno_2011': -1.5797425879990783}),\n",
       " (40,\n",
       "  {'model': <lda.lda.LDA at 0x7f777c07d208>,\n",
       "   'cao_juan_2009': 0.11013624472342246,\n",
       "   'arun_2010': 4.853368419225177,\n",
       "   'coherence_mimno_2011': -1.6514230985163838})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_by_topics = results_by_parameter(eval_results, 'n_topics')\n",
    "eval_results_by_topics[:3]  # again only the first three models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the results for each metric across the specified range of number of topics using [plot_eval_results()](api.rst#tmtoolkit.topicmod.visualize.plot_eval_results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.visualize import plot_eval_results\n",
    "\n",
    "plot_eval_results(eval_results_by_topics);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results suggest to set the number of topics, `n_topics`, to 50 and alpha to `0.02`. We don't have to generate a model with these hyperparameters again, because it's already in the evaluation results (thanks to `return_models=True`). We extract the model from there in order to use it in the rest of the chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 0.02, 0.1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tm = [m for k, m in eval_results_by_topics if k == 50][0]['model']\n",
    "best_tm.n_topics, best_tm.alpha, best_tm.eta  # just to make sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common statistics for topic models\n",
    "\n",
    "The [topicmod.model_stats](api.rst#module-tmtoolkit.topicmod.model_stats) module mostly contains functions that compute statistics from the document-topic and topic-word distribution of a topic model and also some helper functions for working with such distributions. We'll start with an important helper function, [generate_topic_labels_from_top_words()]((api.rst#tmtoolkit.topicmod.model_stats.generate_topic_labels_from_top_words))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating labels for topics\n",
    "\n",
    "In topic modeling, topics are numbered because they're *abstract*  they're simply a probability distribution across all words in the vocabulary. Still, it's useful to give them labels for better identification. The function [generate_topic_labels_from_top_words()](api.rst#tmtoolkit.topicmod.model_stats.generate_topic_labels_from_top_words) is very useful for that, as it finds labels according to the most \"relevant\" words in each topic. We'll later see how we can identify the most relevant words per topic using a special [relevance statistic](#Topic-word-relevance). Note that you can adjust the weight of the relevance measure for the ranking by using the parameter `lambda_` which is in range $[0, 1]$.\n",
    "\n",
    "The function requires at least the topic-word and document-topic distributions from the model, the document lengths and the vocabulary. It then finds the minimum number of relevant words that uniquely label each topic. You can also use a fixed number for that minimum number with the parameter `n_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_record_rock', '2_referendum_vote', '3_car_reportedly',\n",
       "       '4_help_ability', '5_air_force', '6_find_drug', '7_food_safety',\n",
       "       '8_order_enter', '9_capacity_million', '10_recall_vehicle'],\n",
       "      dtype='<U24')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.bow.bow_stats import doc_lengths\n",
    "from tmtoolkit.topicmod.model_stats import generate_topic_labels_from_top_words\n",
    "\n",
    "doc_lengths_bg = doc_lengths(dtm_bg)\n",
    "topic_labels = generate_topic_labels_from_top_words(\n",
    "    best_tm.topic_word_,\n",
    "    best_tm.doc_topic_,\n",
    "    doc_lengths_bg,\n",
    "    vocab_bg,\n",
    "    lambda_=0.6\n",
    ")\n",
    "\n",
    "topic_labels[:10]   # showing only the first 5 topics here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, two words are necessary to label each topic uniquely. By default, each label is prefixed with a number. You can change that with the parameter `labels_format`.\n",
    "\n",
    "Let's have a look at the top words for a specific topic. We can use [ldamodel_top_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_topic_words) for that from the module [topicmod.model_io](api.rst#module-tmtoolkit.topicmod.model_io), which we will have a closer look at [later](#Displaying-and-exporting-topic-modeling-results):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "      <th>rank_5</th>\n",
       "      <th>rank_6</th>\n",
       "      <th>rank_7</th>\n",
       "      <th>rank_8</th>\n",
       "      <th>rank_9</th>\n",
       "      <th>rank_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10_recall_vehicle</th>\n",
       "      <td>recall (0.07373)</td>\n",
       "      <td>vehicle (0.05172)</td>\n",
       "      <td>car (0.03338)</td>\n",
       "      <td>2015 (0.02605)</td>\n",
       "      <td>cause (0.02605)</td>\n",
       "      <td>company (0.02605)</td>\n",
       "      <td>include (0.02605)</td>\n",
       "      <td>2014 (0.02605)</td>\n",
       "      <td>fire (0.01871)</td>\n",
       "      <td>level (0.01504)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             rank_1             rank_2         rank_3          rank_4           rank_5             rank_6  \\\n",
       "topic                                                                                                                       \n",
       "10_recall_vehicle  recall (0.07373)  vehicle (0.05172)  car (0.03338)  2015 (0.02605)  cause (0.02605)  company (0.02605)   \n",
       "\n",
       "                              rank_7          rank_8          rank_9          rank_10  \n",
       "topic                                                                                  \n",
       "10_recall_vehicle  include (0.02605)  2014 (0.02605)  fire (0.01871)  level (0.01504)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_top_topic_words\n",
    "\n",
    "top_topic_word = ldamodel_top_topic_words(best_tm.topic_word_,\n",
    "                                          vocab_bg,\n",
    "                                          row_labels=topic_labels)\n",
    "top_topic_word[top_topic_word.index == '10_recall_vehicle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal topic and word distributions\n",
    "\n",
    "We'll now focus on the marginal topic and word distributions. Let's get the marginal topic distribution first by using [marginal_topic_distrib()](api.rst#tmtoolkit.topicmod.model_stats.marginal_topic_distrib):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00566, 0.02144, 0.01269, 0.00993, 0.00775, 0.01187, 0.01217,\n",
       "       0.01248, 0.02731, 0.01021, 0.01079, 0.01756, 0.01002, 0.00871,\n",
       "       0.01896, 0.02267, 0.02212, 0.01184, 0.01375, 0.0095 , 0.02533,\n",
       "       0.0233 , 0.02307, 0.00638, 0.04622, 0.02352, 0.05468, 0.01701,\n",
       "       0.03019, 0.01418, 0.02923, 0.02074, 0.03795, 0.01413, 0.02126,\n",
       "       0.02138, 0.00654, 0.00981, 0.01801, 0.01419, 0.02214, 0.02156,\n",
       "       0.03424, 0.02314, 0.06307, 0.01903, 0.01363, 0.01762, 0.01606,\n",
       "       0.03497])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import marginal_topic_distrib\n",
    "\n",
    "marg_topic = marginal_topic_distrib(best_tm.doc_topic_, doc_lengths_bg)\n",
    "marg_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The marginal topic distribution can be interpreted as the \"importance\" of each topic for the whole corpus. Let's get the sorted indices into `topic_labels` with `np.argsort()` and get the top five topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['45_get_go', '27_china_chinese', '25_trump_president',\n",
       "       '33_kill_group', '50_year_first'], dtype='<U24')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argsort() gives ascending order, hence reverse via [::-1]\n",
    "topic_labels[np.argsort(marg_topic)[::-1][:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we can get the marginal word distribution with [marginal_word_distrib()](api.rst#tmtoolkit.topicmod.model_stats.marginal_word_distrib) from the model's topic-word distribution and the marginal topic distribution. We'll use this to list the most probable words for the corpus. As expected, these are mostly quite common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['year', 'china', 'us', 'trump', 'people', 'president', 'one',\n",
       "       'country', 'company', 'new'], dtype='<U15')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import marginal_word_distrib\n",
    "\n",
    "marg_word = marginal_word_distrib(best_tm.topic_word_, marg_topic)\n",
    "vocab_bg[np.argsort(marg_word)[::-1][:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two helper functions exist for this purpose: [most_probable_words()](api.rst#tmtoolkit.topicmod.model_stats.most_probable_words) and [least_probable_words()](api.rst#tmtoolkit.topicmod.model_stats.least_probable_words) sort the vocabulary according to the marginal probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['year', 'china', 'us', 'trump', 'people', 'president', 'one',\n",
       "       'country', 'company', 'new'], dtype='<U15')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import most_probable_words, least_probable_words\n",
    "\n",
    "most_probable_words(vocab_bg, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths_bg,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['17', 'implement', 'reject', 'immediately', 'representative',\n",
       "       'attention', 'highly', 'responsibility', 'quarter', 'ongoing'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_probable_words(vocab_bg, best_tm.topic_word_,\n",
    "                     best_tm.doc_topic_, doc_lengths_bg,\n",
    "                     n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word distinctiveness and saliency\n",
    "\n",
    "Word *distinctiveness* and *saliency* (see below) help to identify the most \"informative\" words in a corpus given its topic model. Both measures are introduced in [Chuang et al. 2012](https://dl.acm.org/citation.cfm?id=2254572).\n",
    "\n",
    "Word distinctiveness is calculated for each word $w$ as\n",
    "\n",
    "$\\text{distinctiveness}(w) = \\sum_T(P(T|w) \\log \\frac{P(T|w)}{P(T)})$.\n",
    "\n",
    "where $P(T)$ is the marginal topic distribution and $P(T|w)$ is the probability of a topic given a word $w$.\n",
    "\n",
    "We can calculate this measure using [word_distinctiveness()](api.rst#tmtoolkit.topicmod.model_stats.word_distinctiveness). To use this measure directly to rank words, we can use [most_distinct_words()](api.rst#tmtoolkit.topicmod.model_stats.most_distinct_words) and [least_distinct_words()](api.rst#tmtoolkit.topicmod.model_stats.least_distinct_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.919  , 0.83647, 1.42262, 0.91743, 1.30967, 0.83061, 1.04771,\n",
       "       1.626  , 1.31854, 1.14434])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import word_distinctiveness, most_distinct_words, least_distinct_words\n",
    "\n",
    "word_distinct = word_distinctiveness(best_tm.topic_word_, marg_topic)\n",
    "word_distinct[:10]   # first 10 words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['food', 'criminal', 'recall', 'son', 'safety', 'facebook',\n",
       "       'protest', 'vehicle', 'record', 'north'], dtype='<U15')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_distinct_words(vocab_bg, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths_bg,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['participate', '24', 'fun', 'room', 'central', 'chinadailycomcn',\n",
       "       'single', '40', 'chairman', 'transfer'], dtype='<U15')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_distinct_words(vocab_bg, best_tm.topic_word_,\n",
    "                     best_tm.doc_topic_, doc_lengths_bg,\n",
    "                     n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word saliency weights each words' distinctiveness by it's marginal probability $P(w)$:\n",
    "\n",
    "$\\text{saliency}(w) = P(w) \\cdot \\text{distinctiveness}(w)$.\n",
    "\n",
    "The respective functions in tmtoolkit are [word_saliency()](api.rst#tmtoolkit.topicmod.model_stats.word_saliency), [most_salient_words()](api.rst#tmtoolkit.topicmod.model_stats.most_salient_words) and [least_salient_words()](api.rst#tmtoolkit.topicmod.model_stats.least_salient_words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00079, 0.00084, 0.00078, 0.00052, 0.00083, 0.00048, 0.00081,\n",
       "       0.0008 , 0.00059, 0.00142])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import word_saliency, most_salient_words, least_salient_words\n",
    "\n",
    "word_sal = word_saliency(best_tm.topic_word_, best_tm.doc_topic_, doc_lengths_bg)\n",
    "word_sal[:10]   # first 10 words in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['china', 'trump', 'us', 'north', 'president', 'year', 'company',\n",
       "       'death', 'people', 'house'], dtype='<U15')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_salient_words(vocab_bg, best_tm.topic_word_,\n",
    "                   best_tm.doc_topic_, doc_lengths_bg,\n",
    "                   n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['participate', 'fun', 'chinadailycomcn', 'central', 'piece', '24',\n",
       "       'route', 'section', 'mission', 'education'], dtype='<U15')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_salient_words(vocab_bg, best_tm.topic_word_,\n",
    "                    best_tm.doc_topic_, doc_lengths_bg,\n",
    "                    n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic-word relevance\n",
    "\n",
    "The topic-word relevance measure as introduced by [Sievert and Shirley 2014](https://www.aclweb.org/anthology/W14-3110/) helps to identify the most relevant words within a topic by also accounting for the marginal probability of each word across the corpus. This is done by integrating a *lift* value, which is the *\"ratio of a term's probability within a topic to its marginal probability across the corpus.\"* (ibid.)\n",
    "\n",
    "Thus for each word $w$, given a topic-word distribution $\\phi$, a topic $t$ and a weight parameter $\\lambda$, it is calculated as:\n",
    "\n",
    "$\\text{relevance}_{\\phi, \\lambda}(w, t) = \\lambda \\log \\phi_{t,w} + (1-\\lambda) \\log \\frac{\\phi_{t,w}}{p(w)}$.\n",
    "\n",
    "The first term $\\log \\phi_{t,w}$ is the log of the topic-word distribution, the second term $\\log \\frac{\\phi_{t,w}}{p(w)}$ is the *log lift* and $\\lambda$ can be used to control the weight between both terms. The lower $\\lambda$, the more weight is put on the lift term, i.e. the more different are the results from the original topic-word distribution.\n",
    "\n",
    "This measure is implemented in [topic_word_relevance()](api.rst#tmtoolkit.topicmod.model_stats.topic_word_relevance). It returns a matrix of the same shape as the topic-word distribution, i.e. each row represents a topic with a (log-transformed) distribution across all words in the vocabulary. Please note that the lambda parameter ends with an underscore: `lambda_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.72165, -4.78791, -4.54399, ..., -4.75864, -4.83761, -4.55602],\n",
       "       [-5.64969, -5.71594, -5.47202, ..., -5.68667, -5.76565, -5.48406],\n",
       "       [-5.24067, -5.30693, -5.06301, ..., -5.27766, -5.35663, -5.07504],\n",
       "       ...,\n",
       "       [-3.09158, -5.55573, -5.31181, ..., -5.52646, -5.60543, -5.32384],\n",
       "       [-5.41848, -5.48474, -5.24082, ..., -5.45547, -5.53444, -5.25285],\n",
       "       [-6.06786, -2.70013, -5.8902 , ..., -6.10484, -6.18382, -2.18866]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import topic_word_relevance\n",
    "\n",
    "topic_word_rel = topic_word_relevance(best_tm.topic_word_, best_tm.doc_topic_,\n",
    "                                      doc_lengths_bg, lambda_=0.6)\n",
    "topic_word_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that it's 50 topics across all words in the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 866)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word_rel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two functions can be used to get the most or least relevant words for a topic: [most_relevant_words_for_topic()](api.rst#tmtoolkit.topicmod.model_stats.most_relevant_words_for_topic) and [least_relevant_words_for_topic()](api.rst#tmtoolkit.topicmod.model_stats.least_relevant_words_for_topic). You can select the topic with the `topic` parameter which is a **zero-based topic index**.\n",
    "\n",
    "We'll do it for topic with index 9, which is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10_recall_vehicle'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_labels[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['recall', 'vehicle', 'car', '2014', 'cause', 'fire', '2015', '29',\n",
       "       'include', 'hit'], dtype='<U15')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import most_relevant_words_for_topic, least_relevant_words_for_topic\n",
    "\n",
    "most_relevant_words_for_topic(vocab_bg, topic_word_rel, topic=9, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['year', 'china', 'trump', 'people', 'president', 'one', 'country',\n",
       "       'new', 'house', 'two'], dtype='<U15')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "least_relevant_words_for_topic(vocab_bg, topic_word_rel, topic=9, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering topics\n",
    "\n",
    "With the function [filter_topics()](api.rst#tmtoolkit.topicmod.model_stats.filter_topics), you can filter the topics according to their topic-word distribution and the following search criteria:\n",
    "\n",
    "- `w`: one or more search patterns according to the [common parameters for pattern matching](preprocessing.ipynb#Common-parameters-for-pattern-matching-functions)\n",
    "- `top_n`: pattern match(es) must occur in the first `top_n` most probable words in the topic\n",
    "- `thresh`: matched words' probability must be above this threshold\n",
    "\n",
    "You must specify at least one of `top_n` and `thresh`, but you can also specify both. The function returns an array of topic indices (which start with zero!).\n",
    "\n",
    "Let's find all topics that have the word \"trump\" in the top 5 most probable words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 20, 24])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import filter_topics\n",
    "\n",
    "found_topics = filter_topics('trump', vocab_bg,\n",
    "                             best_tm.topic_word_, top_n=5)\n",
    "found_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these indices with our `topic_labels`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12_ryan_democrats', '21_day_share', '25_trump_president'],\n",
       "      dtype='<U24')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to select all topics where *any* of the words matched by the glob patterns (`match_type='glob'`) `\"trump\"` *or* `\"russia*\"` achieve at least a probability of 0.01 (`thresh=0.01`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12_ryan_democrats', '14_protest_young', '21_day_share',\n",
       "       '24_criminal_domestic', '25_trump_president', '39_russia_moscow',\n",
       "       '47_russia_border'], dtype='<U24')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_topics = filter_topics(['trump', 'russia*'], vocab_bg,\n",
    "                             best_tm.topic_word_, thresh=0.01, match_type='glob')\n",
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we specify `cond='all'`, *all* patterns must have at least one match (here in the top 50 list of words per topic):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12_ryan_democrats'], dtype='<U24')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_topics = filter_topics(['trump', 'russia*'], vocab_bg,\n",
    "                             best_tm.topic_word_, top_n=50, match_type='glob',\n",
    "                             cond='all')\n",
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also pass a topic-word relevance matrix instead of a topic-word probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['12_ryan_democrats', '25_trump_president'], dtype='<U24')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_topics = filter_topics('trump', vocab_bg,\n",
    "                             topic_word_rel, top_n=5)\n",
    "topic_labels[found_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excluding topics\n",
    "\n",
    "It is often the case that some topics of a topic model rank a lot of uninformative (e.g. very common) words the highest. This is results in some uninformative topics, which you may want to exclude from further analysis. Note that if a large fraction of topics seems uninformative, it points to a problem with your topic model and/or your preprocessing steps. You should [evaluate](#Evaluation-of-topic-models) your candidate models carefully with the mentioned metrics and/or adjust your text preprocessing pipeline.\n",
    "\n",
    "The function [exclude_topics()](api.rst#tmtoolkit.topicmod.model_stats.exclude_topics) allows to remove a specified set of topics from the document-topic and topic-word distributions. You need to pass the **zero-based** indices of the topics that you want to remove, and both distributions.\n",
    "\n",
    "In this example, I identified the following topics as uninformative (by looking at the top ranked words either by topic-word distribution or topic-word relevance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['20_son_site', '28_office_man', '31_support_time', '45_get_go',\n",
       "       '50_year_first'], dtype='<U24')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uninform_topics = [19, 27, 30, 44, 49]\n",
    "topic_labels[uninform_topics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pass these indices to [exclude_topics()](api.rst#tmtoolkit.topicmod.model_stats.exclude_topics) along with the topic model distributions. We'll get back new, filtered, distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 45), (45, 866))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_stats import exclude_topics\n",
    "\n",
    "new_doc_topic, new_topic_word, new_topic_mapping = \\\n",
    "    exclude_topics(uninform_topics, best_tm.doc_topic_,\n",
    "                best_tm.topic_word_, return_new_topic_mapping=True)\n",
    "new_doc_topic.shape, new_topic_word.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the new distributions' shapes that we now have 45 instead of 50 topics, because we removed five of them. We shouldn't forget to also update the topic labels and remove the unwanted topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1_record_rock', '2_referendum_vote', '3_car_reportedly',\n",
       "       '4_help_ability', '5_air_force', '6_find_drug', '7_food_safety',\n",
       "       '8_order_enter', '9_capacity_million', '10_recall_vehicle',\n",
       "       '11_season_third', '12_ryan_democrats', '13_air_commission',\n",
       "       '14_protest_young', '15_campaign_news', '16_death_murder',\n",
       "       '17_north_action', '18_facebook_review', '19_north_woman',\n",
       "       '21_day_share', '22_south_visit', '23_year_energy',\n",
       "       '24_criminal_domestic', '25_trump_president', '26_child_home',\n",
       "       '27_china_chinese', '29_house_white', '30_opposition_bank',\n",
       "       '32_police_arrest', '33_kill_group', '34_president_security',\n",
       "       '35_election_party', '36_eu_uk', '37_board_solution',\n",
       "       '38_rule_concern', '39_russia_moscow', '40_father_new',\n",
       "       '41_water_per', '42_water_people', '43_company_manufacturing',\n",
       "       '44_product_market', '46_court_case', '47_russia_border',\n",
       "       '48_growth_tax', '49_hospital_care'], dtype='<U24')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_topic_labels = np.delete(topic_labels, uninform_topics)\n",
    "new_topic_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying and exporting topic modeling results\n",
    "\n",
    "The [topicmod.model_io](api.rst#module-tmtoolkit.topicmod.model_io) module provides several functions for displaying and exporting topic modeling results, i.e. results derived from the document-topic and topic-word distribution of a given topic model.\n",
    "\n",
    "We already used [ldamodel_top_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_topic_words) briefly, which generates a dataframe with the top words from a topic-word distribution. You can also use the topic-word relevance matrix instead. With `top_n` we can control the number of top words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "      <th>rank_5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic_1</th>\n",
       "      <td>record (-0.2566)</td>\n",
       "      <td>rock (-0.6573)</td>\n",
       "      <td>best (-0.7433)</td>\n",
       "      <td>list (-1.149)</td>\n",
       "      <td>mike (-1.162)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_2</th>\n",
       "      <td>referendum (-0.4418)</td>\n",
       "      <td>vote (-0.4827)</td>\n",
       "      <td>government (-1.178)</td>\n",
       "      <td>street (-1.2)</td>\n",
       "      <td>next (-1.286)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic_3</th>\n",
       "      <td>car (-0.8822)</td>\n",
       "      <td>reportedly (-0.9954)</td>\n",
       "      <td>white (-1.008)</td>\n",
       "      <td>vehicle (-1.08)</td>\n",
       "      <td>individual (-1.198)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       rank_1                rank_2               rank_3           rank_4               rank_5\n",
       "topic                                                                                                         \n",
       "topic_1      record (-0.2566)        rock (-0.6573)       best (-0.7433)    list (-1.149)        mike (-1.162)\n",
       "topic_2  referendum (-0.4418)        vote (-0.4827)  government (-1.178)    street (-1.2)        next (-1.286)\n",
       "topic_3         car (-0.8822)  reportedly (-0.9954)       white (-1.008)  vehicle (-1.08)  individual (-1.198)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using relevance matrix here and showing only the first 3 topics\n",
    "ldamodel_top_topic_words(topic_word_rel, vocab_bg, top_n=5)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values in parantheses are the corresponding values from the matrix for that word in that topic. They're negative because of the log transformation that is applied in the topic-word relevance measure.\n",
    "\n",
    "A similar function can be used for the document-topic distribution: [ldamodel_top_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_top_doc_topics). Here, `top_n` controls the number of top-ranked topics to export. This time, we use the filtered document-topic distribution `new_doc_topics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>document</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1041</th>\n",
       "      <td>22_south_visit (0.8199)</td>\n",
       "      <td>15_campaign_news (0.06708)</td>\n",
       "      <td>34_president_security (0.06192)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1065</th>\n",
       "      <td>27_china_chinese (0.4759)</td>\n",
       "      <td>35_election_party (0.3074)</td>\n",
       "      <td>40_father_new (0.1389)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1099</th>\n",
       "      <td>25_trump_president (0.3958)</td>\n",
       "      <td>8_order_enter (0.3464)</td>\n",
       "      <td>12_ryan_democrats (0.2104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1169</th>\n",
       "      <td>33_kill_group (0.4507)</td>\n",
       "      <td>47_russia_border (0.1984)</td>\n",
       "      <td>37_board_solution (0.1398)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewsArticles-1174</th>\n",
       "      <td>33_kill_group (0.6924)</td>\n",
       "      <td>3_car_reportedly (0.2984)</td>\n",
       "      <td>49_hospital_care (0.000213)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        rank_1                      rank_2                           rank_3\n",
       "document                                                                                                   \n",
       "NewsArticles-1041      22_south_visit (0.8199)  15_campaign_news (0.06708)  34_president_security (0.06192)\n",
       "NewsArticles-1065    27_china_chinese (0.4759)  35_election_party (0.3074)           40_father_new (0.1389)\n",
       "NewsArticles-1099  25_trump_president (0.3958)      8_order_enter (0.3464)       12_ryan_democrats (0.2104)\n",
       "NewsArticles-1169       33_kill_group (0.4507)   47_russia_border (0.1984)       37_board_solution (0.1398)\n",
       "NewsArticles-1174       33_kill_group (0.6924)   3_car_reportedly (0.2984)      49_hospital_care (0.000213)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_top_doc_topics\n",
    "\n",
    "ldamodel_top_doc_topics(new_doc_topic, doc_labels, top_n=3,\n",
    "                        topic_labels=new_topic_labels)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at one of these documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The leader China never forgot\n",
      "\n",
      "In new biography, author recalls former prime minister Edward Heath's meetings with nation's legendary figures Michael McManus believes Edward Heath was a pivotal figure in China's opening up to the West. The former British prime minister - who is the subject of the author's new biography - famously first met with Chairman Mao in 1974 and was a regular visitor thereafter to the country that has since become the world's second-largest economy. \"They (the Chinese) re ...\n"
     ]
    }
   ],
   "source": [
    "print(corpus['NewsArticles-1065'][:500], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also two functions that generate datatables for the full topic-word and document-topic distributions: [ldamodel_full_topic_words()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_full_topic_words) and [ldamodel_full_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.ldamodel_full_doc_topics). The output of both functions is naturally quite big, as long as you're not working with a \"toy dataset\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool { background: #DDDD99; }\n",
       ".datatable .obj  { background: #565656; }\n",
       ".datatable .int  { background: #5D9E5D; }\n",
       ".datatable .real { background: #4040CC; }\n",
       ".datatable .str  { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n",
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>_topic</th><th>10</th><th>100</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th><th>16</th><th>17</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>1_record_rock</td><td>0.000527426</td><td>0.000527426</td><td>0.000527426</td><td>0.000527426</td><td>0.000527426</td><td>0.000527426</td><td>0.000527426</td><td>0.0110759</td><td>0.000527426</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>2_referendum_vote</td><td>0.000208507</td><td>0.000208507</td><td>0.000208507</td><td>0.00229358</td><td>0.000208507</td><td>0.00229358</td><td>0.000208507</td><td>0.000208507</td><td>0.000208507</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>3_car_reportedly</td><td>0.000313873</td><td>0.000313873</td><td>0.000313873</td><td>0.000313873</td><td>0.000313873</td><td>0.000313873</td><td>0.00659134</td><td>0.000313873</td><td>0.000313873</td></tr>\n",
       "    <tr><td class='row_index'>3</td><td>4_help_ability</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td><td>0.000373692</td></tr>\n",
       "    <tr><td class='row_index'>4</td><td>5_air_force</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td><td>0.000439367</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>5 rows &times; 10 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_full_topic_words\n",
    "\n",
    "datatable_topic_word = ldamodel_full_topic_words(new_topic_word,\n",
    "                                                 vocab_bg,\n",
    "                                                 row_labels=new_topic_labels)\n",
    "# displaying only the first 5 topics with the first\n",
    "# 10 words from the vocabulary (which are all numbers)\n",
    "datatable_topic_word[:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='datatable'>\n",
       "  <table class='frame'>\n",
       "  <thead>\n",
       "    <tr class='colnames'><td class='row_index'></td><th>_doc</th><th>1_record_rock</th><th>2_referendum_vote</th><th>3_car_reportedly</th><th>4_help_ability</th></tr>\n",
       "    <tr class='coltypes'><td class='row_index'></td><td class='str' title='str32'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td><td class='real' title='float64'>&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;&#x25AA;</td></tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr><td class='row_index'>0</td><td>NewsArticles-1041</td><td>5.15597e-05</td><td>5.15597e-05</td><td>5.15597e-05</td><td>5.15597e-05</td></tr>\n",
       "    <tr><td class='row_index'>1</td><td>NewsArticles-1065</td><td>0.000198216</td><td>0.000198216</td><td>0.000198216</td><td>0.000198216</td></tr>\n",
       "    <tr><td class='row_index'>2</td><td>NewsArticles-1099</td><td>0.000247219</td><td>0.000247219</td><td>0.000247219</td><td>0.000247219</td></tr>\n",
       "  </tbody>\n",
       "  </table>\n",
       "  <div class='footer'>\n",
       "    <div class='frame_dimensions'>3 rows &times; 5 columns</div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import ldamodel_full_doc_topics\n",
    "\n",
    "datatable_doc_topic = ldamodel_full_doc_topics(new_doc_topic,\n",
    "                                               doc_labels,\n",
    "                                               topic_labels=new_topic_labels)\n",
    "# displaying only the first 3 documents with the first\n",
    "# 5 topics\n",
    "datatable_doc_topic[:3, :5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quick inspection of topics there's also a pair of print functions. We already used [print_ldamodel_topic_words()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_topic_words), but we haven't tried [print_ldamodel_doc_topics()](api.rst#tmtoolkit.topicmod.model_io.print_ldamodel_doc_topics) yet. This prints the `top_n` most probable topics for each document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewsArticles-1041\n",
      "> #1. 22_south_visit (0.819850)\n",
      "> #2. 15_campaign_news (0.067079)\n",
      "> #3. 34_president_security (0.061923)\n",
      "NewsArticles-1065\n",
      "> #1. 27_china_chinese (0.475917)\n",
      "> #2. 35_election_party (0.307433)\n",
      "> #3. 40_father_new (0.138949)\n",
      "NewsArticles-1099\n",
      "> #1. 25_trump_president (0.395797)\n",
      "> #2. 8_order_enter (0.346354)\n",
      "> #3. 12_ryan_democrats (0.210383)\n",
      "NewsArticles-1169\n",
      "> #1. 33_kill_group (0.450744)\n",
      "> #2. 47_russia_border (0.198378)\n",
      "> #3. 37_board_solution (0.139793)\n",
      "NewsArticles-1174\n",
      "> #1. 33_kill_group (0.692439)\n",
      "> #2. 3_car_reportedly (0.298403)\n",
      "> #3. 49_hospital_care (0.000213)\n"
     ]
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import print_ldamodel_doc_topics\n",
    "\n",
    "# subsetting new_doc_topic and doc_labels to get only the first\n",
    "# five documents\n",
    "print_ldamodel_doc_topics(new_doc_topic[:5, :], doc_labels[:5],\n",
    "                          val_labels=new_topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also export the results of a topic model to an Excel file using [save_ldamodel_summary_to_excel()](api.rst#tmtoolkit.topicmod.model_io.save_ldamodel_summary_to_excel). The resulting Excel file will contain the following sheets:\n",
    "\n",
    "- `top_doc_topics_vals`: document-topic distribution with probabilities of top topics per document\n",
    "- `top_doc_topics_labels`: document-topic distribution with labels of top topics per document\n",
    "- `top_doc_topics_labelled_vals`: document-topic distribution combining probabilities and labels of top topics per\n",
    "  document (e.g. `\"topic_12 (0.21)\"`)\n",
    "- `top_topic_word_vals`: topic-word distribution with probabilities of top words per topic\n",
    "- `top_topic_word_labels`: topic-word distribution with top words per (e.g. `\"politics\"`) topic\n",
    "- `top_topic_words_labelled_vals`: topic-word distribution combining probabilities and top words per topic\n",
    "  (e.g. `\"politics (0.08)\"`)\n",
    "- optional if `dtm` is given  `marginal_topic_distrib`: marginal topic distribution\n",
    "\n",
    "Additionally to saving the output to the specified Excel file, the function will also return a dict with the sheets and their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod.model_io import save_ldamodel_summary_to_excel\n",
    "\n",
    "sheets = save_ldamodel_summary_to_excel('data/news_articles_100.xlsx',\n",
    "                                        new_topic_word, new_doc_topic,\n",
    "                                        doc_labels, vocab_bg,\n",
    "                                        dtm = dtm_bg,\n",
    "                                        topic_labels = new_topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly store a topic model to disk for sharing or loading again at a later point in time, there are [save_ldamodel_to_pickle()](api.rst#tmtoolkit.topicmod.model_io.save_ldamodel_to_pickle) and [load_ldamodel_from_pickle()](api.rst#tmtoolkit.topicmod.model_io.load_ldamodel_from_pickle). The function for saving takes a path to a pickle file to create (or update), a topic model object (such as an LDA instance as `best_tm`, but you could also pass a tuple like `(new_doc_topic, new_topic_word)`), the corresponding vocabulary and document labels, and optionally the DTM that was used to create the topic model. The function for loading the data will return the saved data as a dict. We will only show the dict's keys here, as the data itself is too large to be printed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'vocab', 'doc_labels', 'dtm'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tmtoolkit.topicmod.model_io import save_ldamodel_to_pickle, load_ldamodel_from_pickle\n",
    "\n",
    "save_ldamodel_to_pickle('data/news_articles_100.pickle',\n",
    "                        best_tm, vocab_bg, doc_labels,\n",
    "                        dtm = dtm_bg)\n",
    "\n",
    "loaded = load_ldamodel_from_pickle('data/news_articles_100.pickle')\n",
    "loaded.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
